{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f023618-c9bf-4689-9912-af28f33c00b5",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cafc276-869b-4e38-a61c-3a03a14c990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import monai\n",
    "from monai.handlers.utils import from_engine\n",
    "from monai.networks.layers import Norm\n",
    "from monai.data import CacheDataset, decollate_batch\n",
    "import numpy as np\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.transforms import (Transform,AsDiscrete,Activations, Activationsd, Compose, LoadImaged,\n",
    "                              Transposed, ScaleIntensityd, RandAxisFlipd, RandRotated, RandAxisFlipd,\n",
    "                              RandBiasFieldd, ScaleIntensityRangePercentilesd, RandAdjustContrastd,\n",
    "                              RandHistogramShiftd, DivisiblePadd, Orientationd, RandGibbsNoised, Spacingd,\n",
    "                              RandRicianNoised, AsChannelLastd, RandSpatialCropd,ToNumpyd,EnsureChannelFirstd,\n",
    "                              RandSpatialCropSamplesd, RandCropByPosNegLabeld)\n",
    "from monai.data.utils import pad_list_data_collate\n",
    "import pandas as pd\n",
    "import random as rd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "import nibabel as nib\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import pytorch_lightning\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2093c07-6e77-4ba4-a528-2ffb93583c9e",
   "metadata": {},
   "source": [
    "## Wandb login:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c189b28-b862-4135-9f61-ac742c43f886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33malijohnnaqvi6\u001b[0m (\u001b[33mali-john\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb353c-801c-4310-a3ab-bd8dbba5e4e1",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b75f845-a70e-42e3-a1a3-a27206d217a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        \n",
    "        LoadImaged(keys=[\"img\"],image_only=True),\n",
    "        EnsureChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\"],\n",
    "            minv=0.0,\n",
    "            maxv=1.0),\n",
    "        RandRotated(keys=[\"img\"],\n",
    "            range_x=np.pi / 12,\n",
    "            prob=0.5,\n",
    "            keep_size=True,\n",
    "            mode=\"nearest\"),\n",
    "\n",
    "    ]\n",
    ")\n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"img\"],image_only=True),\n",
    "        EnsureChannelFirstd(keys=[\"img\"]),\n",
    "        ScaleIntensityd(keys=[\"img\"],\n",
    "            minv=0.0,\n",
    "            maxv=1.0),\n",
    "        RandRotated(keys=[\"img\"],\n",
    "            range_x=np.pi / 12,\n",
    "            prob=0.5,\n",
    "            keep_size=True,\n",
    "            mode=\"nearest\"),\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def load_data(batch, root_dir):\n",
    "   \n",
    "    data = pd.read_csv(os.path.join(root_dir,'gloabl_ageT2.csv'))\n",
    "    imgs_list = list(data['participant_id'])\n",
    "    age_list = list(data['age'])\n",
    "    length = len(imgs_list)\n",
    "    print(f'Total images: {length}') \n",
    "    test = int(0.90*length)\n",
    "    first = int(0.75*length)\n",
    "\n",
    "    imgs_list_train = imgs_list[0:first]\n",
    "    imgs_list_val = imgs_list[first:test]\n",
    "    imgs_list_test = imgs_list[test:]\n",
    "    age_labels_train = age_list[0:first]\n",
    "    age_labels_val = age_list[first:test]\n",
    "    age_labels_test = age_list[test:]\n",
    "\n",
    "    print('train set', len(imgs_list_train), len(age_labels_train))\n",
    "    print('val set', len(imgs_list_val), len(age_labels_val))\n",
    "\n",
    "    filenames_train = [{\"img\": x, \"age\": y} for (x,y) in zip(imgs_list_train, age_labels_train)]\n",
    "    ds_train = monai.data.Dataset(filenames_train, train_transforms)\n",
    "    train_loader = DataLoader(ds_train, batch_size=batch, shuffle = True, num_workers=2, pin_memory=True, collate_fn=pad_list_data_collate)\n",
    "\n",
    "    filenames_val = [{\"img\": x, \"age\": y} for (x, y) in zip(imgs_list_val, age_labels_val)]\n",
    "    ds_val = monai.data.Dataset(filenames_val, val_transforms)\n",
    "    val_loader = DataLoader(ds_val, batch_size=batch, shuffle=True, num_workers=1, pin_memory=True, collate_fn=pad_list_data_collate)\n",
    "\n",
    "    filenames_test = [{\"img\":x, \"age\":y} for (x,y) in zip(imgs_list_test,age_labels_test)]\n",
    "    ds_test = monai.data.Dataset(filenames_test,val_transforms)\n",
    "    test_loader = DataLoader(ds_test,batch_size=batch,shuffle=True,num_workers=1,pin_memory=True,collate_fn=pad_list_data_collate)\n",
    "    \n",
    "    return ds_train, train_loader, ds_val, val_loader, ds_test,test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb872893-ce33-4ba2-994e-4891f06b90a3",
   "metadata": {},
   "source": [
    "## 3D U-net Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f9d1c19-6d09-45f3-bd75-5f0d459783f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class build_seq_sfcn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv3d(1, 32, kernel_size=3, padding=1), #[2,32,256,256,192]\n",
    "            nn.BatchNorm3d(32),\n",
    "            nn.MaxPool3d((2, 2, 2)),#[2,32,128,128,96]\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(32, 64, kernel_size=3, padding=1),#[2,64,128,128,96]\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.MaxPool3d((2, 2, 2)),#[2,64,64,64,48]\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(64, 128, kernel_size=3, padding=1),#[2,128,64,64,48]\n",
    "            nn.BatchNorm3d(128),\n",
    "            nn.MaxPool3d((2, 2, 2)),#[2,128,32,32,24]\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(128, 256, kernel_size=3, padding=1),#[2,256,32,32,24]\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.MaxPool3d((2, 2, 2)),#[2,256,16,16,12]\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(256, 256, kernel_size=3, padding=1),#[2,256,16,16,12]\n",
    "            nn.BatchNorm3d(256),\n",
    "            nn.MaxPool3d((2, 2, 2)),#[2,256,8,8,6]\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv3d(256, 64, kernel_size=1, padding=1),#[2,64,8,8,6]\n",
    "            nn.BatchNorm3d(64),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.regressor= nn.Sequential(\n",
    "            nn.Conv3d(64, 1, kernel_size=1, padding=1),#[2,1,8,8,6]\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1440, 1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "\n",
    "        glob_age_output = self.features(inputs)\n",
    "        glob_age_output = self.regressor(glob_age_output)\n",
    "\n",
    "\n",
    "        return glob_age_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e470e8b0-0273-4684-b5d2-15924d0e4eac",
   "metadata": {},
   "source": [
    "## Train loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bceaae23-4352-4d66-8c63-124fa550979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, val_loader, model, optimizer, scheduler, max_epochs, root_dir):\n",
    "\n",
    "    metrices = {}\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print('Device set to Cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    model.train()\n",
    "    loss_object  = nn.MSELoss()\n",
    "    best_val_loss = 0.0\n",
    "    best_mae_score = 0.0\n",
    "    for epoch in range(1,max_epochs +1):\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "    \n",
    "        print(\"Epoch \", epoch)\n",
    "        print(\"Train:\", end =\"\")\n",
    "\n",
    "        for step, batch in enumerate(train_loader):\n",
    "            img, age = (batch[\"img\"].cuda(), batch[\"age\"].cuda())\n",
    "            age = age.unsqueeze(1)\n",
    "       \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_glob_age = model(img)\n",
    "\n",
    "            loss = loss_object(pred_glob_age.float(), age.float())\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(\"=\", end = \"\")\n",
    "\n",
    "        train_loss = train_loss/(step+1)\n",
    "        metrices[\"train_loss\"] = train_loss\n",
    "        \n",
    "\n",
    "        print()\n",
    "        print(\"Val:\", end =\"\")\n",
    "        with torch.no_grad():\n",
    "                mae_loss=0.0\n",
    "                for step, batch in enumerate(val_loader):\n",
    "                    img, age = (batch[\"img\"].cuda(), batch[\"age\"].cuda())\n",
    "                    age = age.unsqueeze(1)\n",
    "\n",
    "                    pred_glob_age = model(img)\n",
    "\n",
    "\n",
    "                    loss = loss_object(pred_glob_age.float(), age.float())\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "                    print(\"=\", end = \"\")\n",
    "                print()\n",
    "                val_loss = val_loss/(step+1)\n",
    "                metrices[\"val_loss\"] = val_loss\n",
    "\n",
    "\n",
    "        print(\"Training epoch \", epoch, \", train loss:\", train_loss, \", val loss:\", val_loss, \" | \", optimizer.param_groups[0]['lr'])\n",
    "        wandb.log(metrices)\n",
    "        if epoch == 1:\n",
    "            best_val_loss = val_loss\n",
    "        if val_loss < best_val_loss:\n",
    "            print(\"Saving model\")\n",
    "            best_val_loss = val_loss\n",
    "            state = {\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "\n",
    "            torch.save(state, 'PATH/TO/WHERE/TO/SAVE/MODEL' + f\"model_{epoch}.pth\")\n",
    "        scheduler.step()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896743d6-9227-4be0-a771-fc9c5e698c65",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c6667-4dde-448b-8e59-dfff13eb25ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 3\n",
    "    epochs = 60\n",
    "    root_dir = 'PATH/TO/DATASET/DIRECTORY'\n",
    "    \n",
    "\n",
    "\n",
    "    ds_train, train_loader, ds_val, val_loader = load_data( batch_size, root_dir)\n",
    "    \n",
    "    # Building our 3D UNET model\n",
    "    model = build_seq_sfcn()\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print('device set to Cuda')\n",
    "\n",
    "    else:\n",
    "        print (\"Cuda not found\")\n",
    "        device= torch.device('cpu')\n",
    "    model = model.to(device)\n",
    "    step = 20\n",
    "    gamma=0.5\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate, weight_decay=1e-5, betas=(0.5, 0.999))\n",
    "    scheduler = StepLR(optimizer, step_size=step, gamma=gamma)\n",
    "    wandb.init(\n",
    "    project=\"T2 Global age\",\n",
    "    config={\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"architecture\": \"SC-FN\",\n",
    "    \"dataset\": \"CAMCAN\",\n",
    "    \"epochs\": 70,\n",
    "    }\n",
    ")\n",
    "    \n",
    "    print(\"Start of training...\")\n",
    "    train(train_loader, val_loader, model, optimizer, scheduler, epochs, root_dir)\n",
    "    print(\"End of training...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f643ebf3-f975-4c1b-9f96-0d3bdcb6c101",
   "metadata": {},
   "source": [
    "# Inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47cff6c-142d-4d2b-aa4d-7c568e9ae4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the best saved model\n",
    "state = torch.load('/home/wamika/ml_project/models/global_age/T2/model_59.pth')\n",
    "model = build_seq_sfcn()\n",
    "model.load_state_dict(state['state_dict'])\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5,betas=(0.5, 0.999))\n",
    "optimizer.load_state_dict(state['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac02f91-92b2-4617-a04a-ae6f6c564474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 653\n",
      "train set 489 489\n",
      "val set 98 98\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "root_dir = '/home/wamika/ml_project/anat/'\n",
    "ds_train, train_loader, ds_val, val_loader, ds_test, test_loader = load_data( batch_size, root_dir)\n",
    "differences = []\n",
    "i=0\n",
    "with torch.no_grad():\n",
    "    for step, batch in enumerate(test_loader):\n",
    "                img, age = (batch[\"img\"].cuda(), batch[\"age\"].cuda())\n",
    "                age = age.cpu().numpy()\n",
    "                pred_glob_age = model(img)\n",
    "                pred_glob_age = pred_glob_age.cpu().numpy().squeeze(0)\n",
    "                diff = abs(pred_glob_age-age)\n",
    "                differences.append(diff)\n",
    "                i=i+1\n",
    "                if i==50:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7355099e-a673-4e9a-953a-083ed4e6e481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set MAE: [7.55813675]\n"
     ]
    }
   ],
   "source": [
    "print(f'Test Set MAE: {sum(differences)/len(differences)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
